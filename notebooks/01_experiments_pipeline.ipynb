{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ae2745-7e54-43b2-a51f-2955a6c36e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google.generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google.generativeai)\n",
      "  Downloading google_api_python_client-2.179.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (3.20.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (2.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google.generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google.generativeai) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic->google.generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic->google.generativeai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.68.0)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2024.8.30)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio-1.74.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "   ---------------------------------------- 0.0/155.4 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 122.9/155.4 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 155.4/155.4 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.2/1.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.3/1.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.3 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.1/1.3 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 160.8/160.8 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "   ---------------------------------------- 0.0/216.1 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 143.4/216.1 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 216.1/216.1 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.179.0-py3-none-any.whl (14.0 MB)\n",
      "   ---------------------------------------- 0.0/14.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.0 MB 7.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/14.0 MB 7.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.8/14.0 MB 6.0 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.9/14.0 MB 5.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.9/14.0 MB 5.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.9/14.0 MB 5.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.9/14.0 MB 5.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.9/14.0 MB 5.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.9/14.0 MB 5.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.9/14.0 MB 5.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.0/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.1/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.1/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.2/14.0 MB 2.0 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.4/14.0 MB 2.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.5/14.0 MB 2.1 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.6/14.0 MB 2.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.6/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.6/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.7/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.0/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.0/14.0 MB 2.0 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.1/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.2/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.2/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.3/14.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.5/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.5/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.5/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.5/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.5/14.0 MB 1.7 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.6/14.0 MB 1.7 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.8/14.0 MB 1.8 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 3.0/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.1/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.1/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.2/14.0 MB 1.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.4/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.5/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.6/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.7/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.9/14.0 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.9/14.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 4.2/14.0 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.3/14.0 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.5/14.0 MB 2.1 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 4.7/14.0 MB 2.1 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 4.9/14.0 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.0/14.0 MB 2.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.2/14.0 MB 2.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.4/14.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.6/14.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.8/14.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.9/14.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 6.1/14.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 6.4/14.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 6.5/14.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.7/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.8/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.9/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.0/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.1/14.0 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.1/14.0 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.1/14.0 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.1/14.0 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.1/14.0 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.4/14.0 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.6/14.0 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.8/14.0 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.9/14.0 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.1/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.4/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.4/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.4/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.4/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.4/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.4/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.4/14.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.6/14.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.6/14.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.6/14.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.6/14.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/14.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.9/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 9.0/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 9.0/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 9.1/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 9.2/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.4/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.5/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.7/14.0 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.7/14.0 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 9.8/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 9.9/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 10.0/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 10.1/14.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 10.2/14.0 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.4/14.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.5/14.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.6/14.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.7/14.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.9/14.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.9/14.0 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.2/14.0 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.4/14.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 11.6/14.0 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 11.8/14.0 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.0/14.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.1/14.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.4/14.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.6/14.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.8/14.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.9/14.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.1/14.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.3/14.0 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.5/14.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.7/14.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/14.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/14.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/14.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.0/14.0 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.5 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 174.1/294.5 kB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 286.7/294.5 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 294.5/294.5 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.8 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 194.6/434.8 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  430.1/434.8 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 434.8/434.8 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.74.0-cp312-cp312-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/4.5 MB 6.3 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.3/4.5 MB 5.0 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.4/4.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.4/4.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.6/4.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.7/4.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.9/4.5 MB 2.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.1/4.5 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.2/4.5 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.4/4.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.6/4.5 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.8/4.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.9/4.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.0/4.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.2/4.5 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.5/4.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.8/4.5 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.0/4.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.2/4.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.5/4.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.7/4.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.9/4.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.1/4.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.4/4.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.5/4.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.5/4.5 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.68.0\n",
      "    Uninstalling grpcio-1.68.0:\n",
      "      Successfully uninstalled grpcio-1.68.0\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.179.0 google-auth-2.40.3 google-auth-httplib2-0.2.0 google.generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.74.0 grpcio-status-1.71.2 httplib2-0.22.0 proto-plus-1.26.1 protobuf-5.29.5 rsa-4.9.1 uritemplate-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.32.0 requires protobuf<5,>=3.20, but you have protobuf 5.29.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8435d430-8b14-42f6-b923-ea910fbaeb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_name  months_since_launch_1  months_since_launch_2  \\\n",
      "0  덴마크 하이그릭요거트 400g                  93919                 133758   \n",
      "1   동원맛참 고소참기름 135g                 292450                 418898   \n",
      "2    동원맛참 고소참기름 90g                 230354                 297112   \n",
      "3   동원맛참 매콤참기름 135g                 263078                 380298   \n",
      "4    동원맛참 매콤참기름 90g                 161368                 203075   \n",
      "\n",
      "   months_since_launch_3  months_since_launch_4  months_since_launch_5  \\\n",
      "0                 179243                 190409                 294858   \n",
      "1                 528561                 678933                 863708   \n",
      "2                 397737                 553827                 738092   \n",
      "3                 487890                 710607                 862861   \n",
      "4                 277533                 397054                 418334   \n",
      "\n",
      "   months_since_launch_6  months_since_launch_7  months_since_launch_8  \\\n",
      "0                 311689                 414775                 489801   \n",
      "1                1017089                1302517                1547378   \n",
      "2                 806285                1217979                1192864   \n",
      "3                 855604                1205181                1345530   \n",
      "4                 588231                 668257                 830412   \n",
      "\n",
      "   months_since_launch_9  months_since_launch_10  months_since_launch_11  \\\n",
      "0                 615539                  598717                  672828   \n",
      "1                1698157                 2121413                 2408981   \n",
      "2                1360878                 1634848                 1737353   \n",
      "3                1617348                 1761574                 1819311   \n",
      "4                 854036                 1064972                 1221372   \n",
      "\n",
      "   months_since_launch_12  \n",
      "0                  687760  \n",
      "1                 2663258  \n",
      "2                 2028555  \n",
      "3                 2196006  \n",
      "4                 1362180  \n",
      "Files: submission.csv, monthly_forecast.csv, persona_single_turn_prompt.txt/.pdf, sources_used.json, solution_report.md\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Persona-based Monthly Demand Forecast (2024-07 ~ 2025-06)\n",
    "— product_info → (가격/GRP/ACV 자동 파싱) → 페르소나 시뮬레이션 → submission.csv\n",
    "\n",
    "Input : product_info.csv [product_name, product_feature, category_level_1/2/3]\n",
    "Output: submission.csv (months_since_launch_1..12, int)\n",
    "        monthly_forecast.csv (마지막 제품 디버그용)\n",
    "        persona_single_turn_prompt.txt/.pdf, sources_used.json, solution_report.md\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import numpy as np, pandas as pd\n",
    "import json, random, math, os, datetime as dt, re\n",
    "\n",
    "# ---------- PDF export (optional, 없으면 txt만 저장) ----------\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import A4\n",
    "    from reportlab.pdfgen import canvas as pdfcanvas\n",
    "    _HAS_RL = True\n",
    "except Exception:\n",
    "    _HAS_RL = False\n",
    "\n",
    "# ---------- Dates ----------\n",
    "FORECAST_START = dt.date(2024,7,1)\n",
    "FORECAST_END   = dt.date(2025,6,30)\n",
    "MONTHS = pd.period_range(FORECAST_START, FORECAST_END, freq='M')\n",
    "RNG = np.random.default_rng(42)\n",
    "random.seed(42)\n",
    "\n",
    "# ---------- Sources registry (출처 기록 파일) ----------\n",
    "class SourcesRegistry:\n",
    "    def __init__(self): self._items=[]\n",
    "    def add(self, kind, title, how_used, url=None, notes=\"\"):\n",
    "        self._items.append({\"kind\":kind,\"title\":title,\"url\":url,\"how_used\":how_used,\n",
    "                             \"notes\":notes,\"added_at\":dt.datetime.now().isoformat()})\n",
    "    def to_json(self, path=\"sources_used.json\"):\n",
    "        with open(path,\"w\",encoding=\"utf-8\") as f: json.dump(self._items,f,ensure_ascii=False,indent=2)\n",
    "\n",
    "SOURCES = SourcesRegistry()\n",
    "SOURCES.add('paper','Using LLMs for Market Research (Brand, Israeli, Ngwe, 2024)',\n",
    "            'LLM-as-simulator 절차/싱글턴 프롬프트 설계','(local pdf)')\n",
    "\n",
    "# ---------- Persona schema ----------\n",
    "ATTRIBUTES = [\n",
    "    'age','gender','income_band','region','household_size','lifestyle',\n",
    "    'health_focus','price_sensitivity','brand_loyalty','online_offline_mix',\n",
    "    'channel_preference','promo_reactivity','ad_reach_susceptibility',\n",
    "    'environmental_concern','innovation_seeker'\n",
    "]\n",
    "\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Persona:\n",
    "    persona_id:str; name:str\n",
    "    age:int; gender:str; income_band:str; region:str; household_size:int; lifestyle:str\n",
    "    health_focus:float; price_sensitivity:float; brand_loyalty:float; online_offline_mix:float\n",
    "    channel_preference:str; promo_reactivity:float; ad_reach_susceptibility:float\n",
    "    environmental_concern:float; innovation_seeker:float\n",
    "    weights:Dict[str,float]; monthly_pattern:List[float]\n",
    "\n",
    "# ---------- LLM prompt ----------\n",
    "SINGLE_TURN_PERSONA_PROMPT = (\"\"\"\n",
    "You are a market-simulation engine. Generate N synthetic Korean consumer personas for a **Dongwon new product** launch.\n",
    "Return **valid JSON** only (list of persona objects).\n",
    "Context:\n",
    "- Category: {category}\n",
    "- Product concept: {concept}\n",
    "- Target price (KRW): {price}\n",
    "- Packaging/size: {pack}\n",
    "- Channels: {channels}\n",
    "- Competitors: {competitors}\n",
    "- Target market size (12-month addressable): {market_size}\n",
    "- Launch months: 2024-07 to 2025-06\n",
    "\n",
    "Each persona fields:\n",
    "- persona_id, name\n",
    "- age (18-69), gender (\"남\"|\"여\"), region (서울/수도권/광역시/기타), household_size (1-5)\n",
    "- income_band (\"~2천\",\"2-4천\",\"4-7천\",\"7천~\"), lifestyle (≤12 chars)\n",
    "- health_focus, price_sensitivity, brand_loyalty, online_offline_mix, promo_reactivity,\n",
    "  ad_reach_susceptibility, environmental_concern, innovation_seeker (0~1)\n",
    "- channel_preference in {channel_vocab}\n",
    "- weights: map **≥10** of {attribute_list} to weights in [-2.0, +2.0] (utility contribution for THIS product)\n",
    "- monthly_pattern: list[12] for 2024-07..2025-06 in 0.6~1.4 (persona seasonality)\n",
    "\n",
    "Constraints: diversify personas; JSON only (no comments/trailing commas).\n",
    "\"\"\").strip()\n",
    "\n",
    "def _build_single_turn_prompt(category, concept, price, pack, channels, competitors, market_size, channel_vocab):\n",
    "    return SINGLE_TURN_PERSONA_PROMPT.format(\n",
    "        category=category, concept=concept, price=price, pack=pack,\n",
    "        channels=\", \".join(channels), competitors=\", \".join(competitors),\n",
    "        market_size=f\"{market_size:,}\", channel_vocab=channel_vocab, attribute_list=ATTRIBUTES\n",
    "    )\n",
    "\n",
    "def save_single_turn_prompt(category, concept, price, pack, channels, competitors, market_size, channel_vocab):\n",
    "    text = _build_single_turn_prompt(category, concept, price, pack, channels, competitors, market_size, channel_vocab)\n",
    "    with open('persona_single_turn_prompt.txt','w',encoding='utf-8') as f: f.write(text)\n",
    "    if _HAS_RL:\n",
    "        c = pdfcanvas.Canvas('persona_single_turn_prompt.pdf', pagesize=A4)\n",
    "        w,h = A4; y=h-50\n",
    "        for line in text.split('\\n'):\n",
    "            while len(line)>100:\n",
    "                c.drawString(40,y,line[:100]); y-=14; line=line[100:]; \n",
    "                if y<50: c.showPage(); y=h-50\n",
    "            c.drawString(40,y,line); y-=14\n",
    "            if y<50: c.showPage(); y=h-50\n",
    "        c.save()\n",
    "\n",
    "# ---------- LLM adapter (Gemini version) ----------\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "\n",
    "class LLMAdapter:\n",
    "    def __init__(self, model=\"gemini-1.5-flash-latest\"):\n",
    "        self.model = model\n",
    "        api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise RuntimeError(\"환경변수 GOOGLE_API_KEY 가 설정되지 않았습니다.\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model_client = genai.GenerativeModel(self.model)\n",
    "\n",
    "    def _extract_json_array(self, text: str) -> list:\n",
    "        # 1) 코드펜스 제거\n",
    "        text = re.sub(r\"^```(?:json)?\\s*\", \"\", text.strip())\n",
    "        text = re.sub(r\"\\s*```$\", \"\", text.strip())\n",
    "        # 2) 본문에서 첫 번째 JSON 배열만 추출\n",
    "        m = re.search(r\"\\[\\s*{.*}\\s*\\]\", text, flags=re.S)\n",
    "        if not m:\n",
    "            # 백틱·주석 등 섞였을 가능성 → 전체에서 중괄호 배열만 다시 시도\n",
    "            raise ValueError(\"LLM 출력에서 JSON 배열을 찾지 못했습니다.\")\n",
    "        return json.loads(m.group(0))\n",
    "\n",
    "    def generate(self, n:int, prompt:str):\n",
    "        msg = prompt.replace(\"Generate N\", f\"Generate {n}\")\n",
    "        try:\n",
    "            rsp = self.model_client.generate_content(msg)\n",
    "            # Gemini python SDK는 보통 rsp.text에 순수 텍스트 제공\n",
    "            text = getattr(rsp, \"text\", None)\n",
    "            if not text:\n",
    "                # 후보 파트 합성 (예외 케이스)\n",
    "                try:\n",
    "                    parts = rsp.candidates[0].content.parts\n",
    "                    text = \"\".join(getattr(p, \"text\", \"\") for p in parts)\n",
    "                except Exception:\n",
    "                    text = \"\"\n",
    "            data = self._extract_json_array(text)\n",
    "            personas = [Persona(**d) for d in data]\n",
    "            return personas\n",
    "        except Exception as e:\n",
    "            print(f\"[LLMAdapter] Gemini 응답 파싱 실패: {e}\")\n",
    "            print(\"→ 규칙 기반 페르소나로 폴백합니다.\")\n",
    "            return generate_personas_rule_based(n)\n",
    "# ---------- Rule-based personas ----------\n",
    "GENDERS=['남','여']; REGIONS=['서울','수도권','광역시','기타']\n",
    "INCOME=['~2천','2-4천','4-7천','7천~']; CHANNELS=['hypermarket','convenience','ecommerce','SSM']\n",
    "LIFESTYLES=['활동적','가성비','워라밸','건강지향','육아','미식','트렌디','야근많음']\n",
    "\n",
    "def _rand_weights()->Dict[str,float]:\n",
    "    return {a: float(np.clip(np.random.normal(0,0.7),-2,2)) for a in ATTRIBUTES}\n",
    "\n",
    "def _rand_monthly_pattern()->List[float]:\n",
    "    base=np.ones(12); \n",
    "    for k,v in {2:1.08, 8:1.10, 9:1.06}.items(): base[k]*=v\n",
    "    base*=np.random.normal(1.0,0.05,12)\n",
    "    pat=(base/base.mean())\n",
    "    return list(np.clip(pat,0.6,1.4))\n",
    "\n",
    "def generate_personas_rule_based(n:int)->List[Persona]:\n",
    "    out=[]\n",
    "    for i in range(n):\n",
    "        out.append(Persona(\n",
    "            persona_id=f\"P{i+1:03d}\", name=f\"홍길{'동' if i%2==0 else '순'}{i%10}\",\n",
    "            age=int(np.random.randint(20,66)), gender=random.choice(GENDERS),\n",
    "            region=random.choice(REGIONS), household_size=int(np.random.randint(1,5)),\n",
    "            income_band=random.choice(INCOME), lifestyle=random.choice(LIFESTYLES),\n",
    "            health_focus=float(np.clip(np.random.beta(2,3),0,1)),\n",
    "            price_sensitivity=float(np.clip(np.random.beta(3,2),0,1)),\n",
    "            brand_loyalty=float(np.clip(np.random.beta(2,4),0,1)),\n",
    "            online_offline_mix=float(np.random.rand()),\n",
    "            channel_preference=random.choice(CHANNELS),\n",
    "            promo_reactivity=float(np.clip(np.random.beta(2,2),0,1)),\n",
    "            ad_reach_susceptibility=float(np.clip(np.random.beta(2,2),0,1)),\n",
    "            environmental_concern=float(np.clip(np.random.beta(2,3),0,1)),\n",
    "            innovation_seeker=float(np.clip(np.random.beta(2,2),0,1)),\n",
    "            weights=_rand_weights(), monthly_pattern=_rand_monthly_pattern()\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "# ---------- Demand model ----------\n",
    "@dataclass\n",
    "class MarketCalendar:\n",
    "    price_krw:Dict[pd.Period,float]; discount_rate:Dict[pd.Period,float]\n",
    "    ad_grps:Dict[pd.Period,float]; distribution:Dict[pd.Period,float]; competitor_pressure:Dict[pd.Period,float]\n",
    "\n",
    "def default_calendar(base_price:int=3500)->MarketCalendar:\n",
    "    price={m:float(base_price) for m in MONTHS}\n",
    "    disc={m:(0.12 if m.month in (9,10,2) else 0.0) for m in MONTHS}\n",
    "    ad={m:200.0 for m in MONTHS}\n",
    "    for m in MONTHS:\n",
    "        if m.month in (7,8): ad[m]=400.0\n",
    "    dist={m:min(1.0,0.35+0.08*i) for i,m in enumerate(MONTHS)}\n",
    "    comp={m:1.0 for m in MONTHS}\n",
    "    return MarketCalendar(price,disc,ad,dist,comp)\n",
    "\n",
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    population:int; base_awareness:float; base_trial_rate:float; repeat_rate:float\n",
    "    price_elasticity:float; ad_effect_per_100grp:float; promo_price_pass_through:float; noise_sd:float=0.05\n",
    "\n",
    "def _sigmoid(x:float)->float: return 1/(1+math.exp(-x))\n",
    "\n",
    "import math\n",
    "def _persona_utility(p:Persona, mi:int, cfg:SimulationConfig, cal:MarketCalendar, period:pd.Period)->float:\n",
    "    wsum=0.0\n",
    "    for k,v in p.weights.items():\n",
    "        val=getattr(p,k,None)\n",
    "        if val is None: continue\n",
    "        if isinstance(val,str) and k in ('gender','region','income_band','channel_preference','lifestyle'):\n",
    "            val_num=(hash((k,val))%7)/6.0\n",
    "        else:\n",
    "            val_num=float(val) if not isinstance(val,str) else 0.5\n",
    "        wsum+=v*val_num\n",
    "    season=p.monthly_pattern[mi]\n",
    "    ad=cfg.ad_effect_per_100grp*(cal.ad_grps[period]/100.0)*p.ad_reach_susceptibility\n",
    "    net_price=cal.price_krw[period]*(1.0-cfg.promo_price_pass_through*cal.discount_rate[period])\n",
    "    price_term=cfg.price_elasticity*math.log(max(net_price,1.0)/1000.0)*p.price_sensitivity\n",
    "    comp=math.log(cal.competitor_pressure[period])\n",
    "    dist=0.1*cal.distribution[period]\n",
    "    return wsum+ad+dist+(-0.3*comp)-0.5+0.2*season+price_term\n",
    "\n",
    "def simulate_monthly_demand(personas:List[Persona], cfg:SimulationConfig, cal:MarketCalendar, export_csv=True)->pd.DataFrame:\n",
    "    rows=[]; cum_trials=0.0\n",
    "    for mi,period in enumerate(MONTHS):\n",
    "        probs=[]\n",
    "        for p in personas:\n",
    "            u=_persona_utility(p,mi,cfg,cal,period)\n",
    "            base=_sigmoid(u)\n",
    "            aware=min(1.0, cfg.base_awareness+0.15*(mi/11.0))\n",
    "            trial=cfg.base_trial_rate*base\n",
    "            probs.append(aware*trial*cal.distribution[period])\n",
    "        exp_trials=cfg.population*np.mean(probs)\n",
    "        cum_trials+=exp_trials\n",
    "        repeats=cfg.repeat_rate*cum_trials*0.2\n",
    "        demand=max(0.0,(exp_trials+repeats)*math.exp(np.random.normal(0,cfg.noise_sd)))\n",
    "        rows.append({'month':period.to_timestamp('M'),\n",
    "                     'trial_units':exp_trials,'repeat_units':repeats,'total_units':demand,\n",
    "                     'distribution':cal.distribution[period],'avg_price':cal.price_krw[period],\n",
    "                     'discount_rate':cal.discount_rate[period],'ad_grps':cal.ad_grps[period]})\n",
    "    df=pd.DataFrame(rows)\n",
    "    if export_csv: df.to_csv('monthly_forecast.csv',index=False)\n",
    "    return df\n",
    "\n",
    "# ---------- 텍스트 → 가격/GRP/ACV ----------\n",
    "_PREMIUM_TABLE={'프리미엄':0.10,'고단백':0.08,'락토프리':0.07,'저나트륨':0.03,'유기':0.05,'친환경':0.05}\n",
    "_BASE_UNIT_PRICE={'참치캔':2000/100.0,'액상조미료':900/100.0,'발효유':1100/100.0,'커피-CUP':640/100.0,'고급축산캔':2200/100.0}\n",
    "\n",
    "def _extract_size(name:str)->Tuple[float,str]:\n",
    "    m=re.search(r'(\\d+(?:\\.\\d+)?)\\s*(g|ml|mL|G|ML)', name)\n",
    "    if not m:\n",
    "        if '커피' in name: return 250.0,'mL'\n",
    "        if '요거트' in name or '발효유' in name: return 400.0,'g'\n",
    "        if '참치' in name: return 90.0,'g'\n",
    "        if '조미' in name: return 500.0,'g'\n",
    "        if '축산' in name: return 200.0,'g'\n",
    "        return 180.0,'g'\n",
    "    v,u=float(m.group(1)),m.group(2).lower()\n",
    "    return v, ('mL' if 'ml' in u else 'g')\n",
    "\n",
    "def _estimate_list_price(row:pd.Series)->int:\n",
    "    name=str(row.get('product_name','')); feat=str(row.get('product_feature',''))\n",
    "    c2=str(row.get('category_level_2','')); c3=str(row.get('category_level_3',''))\n",
    "    size,unit=_extract_size(name)\n",
    "    if '참치캔' in c3 or '참치' in c2: per=_BASE_UNIT_PRICE['참치캔']\n",
    "    elif '조미료' in c3: per=_BASE_UNIT_PRICE['액상조미료']\n",
    "    elif '발효유' in c2 or '요거트' in name: per=_BASE_UNIT_PRICE['발효유']\n",
    "    elif '커피' in c2 or 'CUP' in c3: per=_BASE_UNIT_PRICE['커피-CUP']\n",
    "    elif '축산캔' in c2: per=_BASE_UNIT_PRICE['고급축산캔']\n",
    "    else: per=1000/100.0\n",
    "    price=per*size\n",
    "    prem=sum(v for k,v in _PREMIUM_TABLE.items() if k in feat)\n",
    "    if '프리미엄' in name: prem+=0.10\n",
    "    return int(round(price*(1.0+prem),-1))\n",
    "\n",
    "def _parse_month_ranges(text:str)->List[int]:\n",
    "    res=[]\n",
    "    for m in re.finditer(r'(\\d{1,2})\\s*-\\s*(\\d{1,2})\\s*월', text): a,b=int(m.group(1)),int(m.group(2)); res+=list(range(a,b+1))\n",
    "    for m in re.finditer(r'(?<!-)\\b(\\d{1,2})\\s*월', text): res.append(int(m.group(1)))\n",
    "    return sorted(set([x for x in res if 1<=x<=12]))\n",
    "\n",
    "def enrich_calendar_from_features(cal:MarketCalendar, feat:str, name:str)->None:\n",
    "    months={m.month:m for m in MONTHS}; lower=feat.lower()\n",
    "    for m in MONTHS: cal.ad_grps[m]=200.0\n",
    "    if '광고 x' in lower or '광고x' in lower:\n",
    "        for m in MONTHS: cal.ad_grps[m]=120.0\n",
    "    if any(k in lower for k in ['광고 진행','tv','youtube','sns']):\n",
    "        for mm in _parse_month_ranges(feat):\n",
    "            if mm in months: cal.ad_grps[months[mm]]=max(cal.ad_grps[months[mm]],450.0)\n",
    "    if '엘리베이터 광고' in feat:\n",
    "        for mm in _parse_month_ranges(feat):\n",
    "            if mm in months: cal.ad_grps[months[mm]]+=100.0\n",
    "    if 'sns 바이럴' in feat:\n",
    "        for mm in _parse_month_ranges(feat):\n",
    "            if mm in months: cal.ad_grps[months[mm]]=max(cal.ad_grps[months[mm]],250.0)\n",
    "    for m in MONTHS: cal.discount_rate[m]=0.12 if m.month in (9,10,2) else 0.0\n",
    "    if any(k in feat for k in ['행사','프로모션','기획']):\n",
    "        for mm in _parse_month_ranges(feat):\n",
    "            if mm in months: cal.discount_rate[months[mm]]=min(0.2, cal.discount_rate[months[mm]]+0.05)\n",
    "    start,step=0.35,0.08\n",
    "    if any(k in name for k in ['CUP','컵','커피']): start,step=0.45,0.10\n",
    "    if '엘리베이터 광고' in feat and any(mm in (6,7,8) for mm in _parse_month_ranges(feat)): start+=0.05\n",
    "    cal.distribution={m:min(1.0,start+step*i) for i,m in enumerate(MONTHS)}\n",
    "\n",
    "# ---------- Heuristics ----------\n",
    "def _infer_channels(c1,c2,c3):\n",
    "    if '발효유' in str(c2): return ['hypermarket','convenience']\n",
    "    if '참치' in str(c2):   return ['hypermarket','SSM','ecommerce']\n",
    "    if '조미료' in str(c3): return ['hypermarket','ecommerce']\n",
    "    if '축산캔' in str(c2): return ['hypermarket','SSM','ecommerce']\n",
    "    if '커피' in str(c2):   return ['convenience','hypermarket']\n",
    "    return ['hypermarket','ecommerce']\n",
    "\n",
    "def _infer_competitors(c2):\n",
    "    if '참치' in str(c2): return ['CJ','오뚜기','사조']\n",
    "    if '조미'  in str(c2): return ['CJ','오뚜기']\n",
    "    if '발효유' in str(c2): return ['빙그레','매일','남양']\n",
    "    if '축산캔' in str(c2): return ['SPAM','롯데','동원']\n",
    "    if '커피' in str(c2):   return ['매일','동서','스타벅스RTD']\n",
    "    return ['CJ','오뚜기','사조']\n",
    "\n",
    "def _infer_market_size(name:str,c2:str='')->int:\n",
    "    base=6_000_000\n",
    "    if '발효유' in c2 or '요거트' in name: base=3_000_000\n",
    "    elif '참치' in c2: base=10_000_000\n",
    "    elif '조미' in c2: base=5_000_000\n",
    "    elif '축산캔' in c2: base=4_000_000\n",
    "    elif '커피' in c2: base=12_000_000\n",
    "    h=(abs(hash(name))%41)/100.0\n",
    "    return int(base*(0.8+h))\n",
    "\n",
    "# ---------- Scenario runner ----------\n",
    "def run_scenario(persona_count:int=400, use_llm:bool=False,\n",
    "                 category:str='식품', concept:str='신제품',\n",
    "                 price:int=3500, pack:str='unit',\n",
    "                 channels:List[str]=['hypermarket','convenience','ecommerce'],\n",
    "                 competitors:List[str]=['CJ','오뚜기','사조'],\n",
    "                 market_size:int=3_200_000,\n",
    "                 calendar:Optional[MarketCalendar]=None,\n",
    "                 ad_effect_mult:float=1.0):\n",
    "    save_single_turn_prompt(category, concept, price, pack, channels, competitors, market_size, CHANNELS)\n",
    "    personas = (LLMAdapter().generate(persona_count, _build_single_turn_prompt(category,concept,price,pack,channels,competitors,market_size,CHANNELS))\n",
    "                if use_llm else generate_personas_rule_based(persona_count))\n",
    "    cal = calendar or default_calendar(price)\n",
    "    cfg = SimulationConfig(population=market_size, base_awareness=0.18, base_trial_rate=0.35,\n",
    "                           repeat_rate=0.55, price_elasticity=-1.2,\n",
    "                           ad_effect_per_100grp=0.10*ad_effect_mult, promo_price_pass_through=0.8,\n",
    "                           noise_sd=0.06)\n",
    "    forecast=simulate_monthly_demand(personas,cfg,cal,export_csv=True)\n",
    "    SOURCES.to_json('sources_used.json'); _write_solution_outline(forecast, persona_count, category, concept, price, pack)\n",
    "    return forecast, personas\n",
    "\n",
    "def _write_solution_outline(forecast:pd.DataFrame, persona_count:int, category:str, concept:str, price:int, pack:str):\n",
    "    last=forecast.tail(1).iloc[0]\n",
    "    md=(f\"# 솔루션 설명 자료(초안)\\n\"\n",
    "        f\"## 개요\\n- 카테고리:{category}\\n- 컨셉:{concept}\\n- 가격:{price:,} / {pack}\\n- 페르소나:{persona_count}\\n\"\n",
    "        f\"## 핵심결과\\n- 12M 합계:{int(forecast['total_units'].sum()):,} EA\\n\"\n",
    "        f\"- 런칭월:{int(forecast.iloc[0]['total_units']):,} EA\\n- 최종월:{int(last['total_units']):,} EA\\n\")\n",
    "    with open('solution_report.md','w',encoding='utf-8') as f: f.write(md)\n",
    "\n",
    "# ---------- One product → 12m ----------\n",
    "def forecast_one_product(row:pd.Series, persona_count:int=400, use_llm:bool=False)->np.ndarray:\n",
    "    global RNG\n",
    "    name=str(row.get('product_name','')).strip()\n",
    "    feat=str(row.get('product_feature','')).strip()\n",
    "    c1=str(row.get('category_level_1','')); c2=str(row.get('category_level_2','')); c3=str(row.get('category_level_3',''))\n",
    "    # 제품별 시드 고정\n",
    "    seed=abs(hash(name))%(2**32-1); RNG=np.random.default_rng(seed); random.seed(seed)\n",
    "    # 가격/시장/채널\n",
    "    price=_estimate_list_price(row)\n",
    "    market_size=_infer_market_size(name,c2); channels=_infer_channels(c1,c2,c3); competitors=_infer_competitors(c2)\n",
    "    # 캘린더 구성\n",
    "    cal=default_calendar(price); enrich_calendar_from_features(cal, feat, name)\n",
    "    # 유명인 보정\n",
    "    celeb=1.0\n",
    "    if '광고모델' in feat and any(k in feat for k in ['안유진','아이돌','연예인']): celeb=1.15\n",
    "    # 패키지 텍스트\n",
    "    size,unit=_extract_size(name); pack=f\"{int(size)}{unit}\"\n",
    "    # 시뮬\n",
    "    df,_=run_scenario(persona_count, use_llm, c1 or '식품', feat[:80] or '신제품',\n",
    "                     price, pack, channels, competitors, market_size, cal, celeb)\n",
    "    y=np.maximum(0, np.round(df['total_units'].values).astype(int))\n",
    "    return y\n",
    "\n",
    "# ---------- Submission ----------\n",
    "def make_submission(product_info_csv:str, out_csv:str='submission.csv', persona_count:int=400, use_llm:bool=False)->pd.DataFrame:\n",
    "    prod=pd.read_csv(product_info_csv)\n",
    "    rows=[]\n",
    "    for _,row in prod.iterrows():\n",
    "        y=forecast_one_product(row, persona_count, use_llm)\n",
    "        rows.append({'product_name':row['product_name'], **{f'months_since_launch_{i+1}':int(y[i]) for i in range(12)}})\n",
    "    sub=pd.DataFrame(rows)\n",
    "    sub.to_csv(out_csv,index=False)\n",
    "    return sub\n",
    "\n",
    "# ---------- main ----------\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        sub=make_submission('product_info.csv','submission.csv',persona_count=400,use_llm=True)\n",
    "        print(sub.head())\n",
    "        print(\"Files: submission.csv, monthly_forecast.csv, persona_single_turn_prompt.txt/.pdf, sources_used.json, solution_report.md\")\n",
    "    except Exception as e:\n",
    "        print(\"Run make_submission(...) with correct CSV. Error:\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd2e3b6-8044-4da9-bae7-a6472631464a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 7\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 6\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 59\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 59\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 56\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 56\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 47\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 47\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 45\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 45\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 44\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "[LLMAdapter] Gemini 파싱 실패: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 44\n",
      "}\n",
      "] → 규칙기반으로 폴백\n",
      "       product_name  months_since_launch_1  months_since_launch_2  \\\n",
      "0  덴마크 하이그릭요거트 400g                  88135                 122971   \n",
      "1   동원맛참 고소참기름 135g                 212719                 307367   \n",
      "2    동원맛참 고소참기름 90g                 163725                 245163   \n",
      "3   동원맛참 매콤참기름 135g                 238608                 331088   \n",
      "4    동원맛참 매콤참기름 90g                 154382                 209352   \n",
      "\n",
      "   months_since_launch_3  months_since_launch_4  months_since_launch_5  \\\n",
      "0                 166054                 194571                 276057   \n",
      "1                 434625                 490547                 675597   \n",
      "2                 327241                 412526                 518714   \n",
      "3                 440164                 647151                 765623   \n",
      "4                 279459                 349196                 458633   \n",
      "\n",
      "   months_since_launch_6  months_since_launch_7  months_since_launch_8  \\\n",
      "0                 312598                 387945                 435586   \n",
      "1                 817839                1031366                1116940   \n",
      "2                 676803                 774441                 895898   \n",
      "3                 944099                1056178                1255072   \n",
      "4                 568185                 725968                 822596   \n",
      "\n",
      "   months_since_launch_9  months_since_launch_10  months_since_launch_11  \\\n",
      "0                 563346                  626002                  666162   \n",
      "1                1404692                 1549504                 1628580   \n",
      "2                1057950                 1207393                 1365751   \n",
      "3                1526427                 1662499                 1893508   \n",
      "4                1010260                 1080045                 1210202   \n",
      "\n",
      "   months_since_launch_12  \n",
      "0                  672726  \n",
      "1                 1760108  \n",
      "2                 1374470  \n",
      "3                 2018467  \n",
      "4                 1345876  \n",
      "Files: submission.csv, monthly_forecast.csv, persona_single_turn_prompt.txt/.pdf, sources_used.json, solution_report.md\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Persona-based Monthly Demand Forecast (2024-07 ~ 2025-06)\n",
    "— product_info → (가격/GRP/ACV 자동 파싱 + 시즌성/정합도) → 페르소나 시뮬레이션 → submission.csv\n",
    "\n",
    "Output:\n",
    "  - submission.csv (months_since_launch_1..12, int)\n",
    "  - monthly_forecast.csv (마지막 제품 디버깅용)\n",
    "  - persona_single_turn_prompt.txt/.pdf, sources_used.json, solution_report.md\n",
    "  - (선택) calibrated_theta.json 이 있으면 파라미터 자동 로드\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import numpy as np, pandas as pd\n",
    "import json, random, math, os, datetime as dt, re\n",
    "\n",
    "# ---------- PDF export (optional) ----------\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import A4\n",
    "    from reportlab.pdfgen import canvas as pdfcanvas\n",
    "    _HAS_RL = True\n",
    "except Exception:\n",
    "    _HAS_RL = False\n",
    "\n",
    "# ---------- Dates ----------\n",
    "FORECAST_START = dt.date(2024,7,1)\n",
    "FORECAST_END   = dt.date(2025,6,30)\n",
    "MONTHS = pd.period_range(FORECAST_START, FORECAST_END, freq='M')\n",
    "RNG = np.random.default_rng(42)\n",
    "random.seed(42)\n",
    "\n",
    "# ---------- Sources registry ----------\n",
    "class SourcesRegistry:\n",
    "    def __init__(self): self._items=[]\n",
    "    def add(self, kind, title, how_used, url=None, notes=\"\"):\n",
    "        self._items.append({\"kind\":kind,\"title\":title,\"url\":url,\"how_used\":how_used,\n",
    "                            \"notes\":notes,\"added_at\":dt.datetime.now().isoformat()})\n",
    "    def to_json(self, path=\"sources_used.json\"):\n",
    "        with open(path,\"w\",encoding=\"utf-8\") as f: json.dump(self._items,f,ensure_ascii=False,indent=2)\n",
    "\n",
    "SOURCES = SourcesRegistry()\n",
    "SOURCES.add('paper','Using LLMs for Market Research (Brand, Israeli, Ngwe, 2024)',\n",
    "            'LLM-as-simulator 절차/싱글턴 프롬프트 설계','(local pdf)')\n",
    "\n",
    "# ---------- Persona schema ----------\n",
    "ATTRIBUTES = [\n",
    "    'age','gender','income_band','region','household_size','lifestyle',\n",
    "    'health_focus','price_sensitivity','brand_loyalty','online_offline_mix',\n",
    "    'channel_preference','promo_reactivity','ad_reach_susceptibility',\n",
    "    'environmental_concern','innovation_seeker'\n",
    "]\n",
    "\n",
    "@dataclass\n",
    "class Persona:\n",
    "    persona_id:str; name:str\n",
    "    age:int; gender:str; income_band:str; region:str; household_size:int; lifestyle:str\n",
    "    health_focus:float; price_sensitivity:float; brand_loyalty:float; online_offline_mix:float\n",
    "    channel_preference:str; promo_reactivity:float; ad_reach_susceptibility:float\n",
    "    environmental_concern:float; innovation_seeker:float\n",
    "    weights:Dict[str,float]; monthly_pattern:List[float]\n",
    "\n",
    "# ---------- LLM prompt ----------\n",
    "SINGLE_TURN_PERSONA_PROMPT = (\"\"\"\n",
    "You are a market-simulation engine. Generate N synthetic Korean consumer personas for a **Dongwon new product** launch.\n",
    "Return **valid JSON** only (list of persona objects).\n",
    "Context:\n",
    "- Category: {category}\n",
    "- Product concept: {concept}\n",
    "- Target price (KRW): {price}\n",
    "- Packaging/size: {pack}\n",
    "- Channels: {channels}\n",
    "- Competitors: {competitors}\n",
    "- Target market size (12-month addressable): {market_size}\n",
    "- Launch months: 2024-07 to 2025-06\n",
    "\n",
    "Each persona fields:\n",
    "- persona_id, name\n",
    "- age (18-69), gender (\"남\"|\"여\"), region (서울/수도권/광역시/기타), household_size (1-5)\n",
    "- income_band (\"~2천\",\"2-4천\",\"4-7천\",\"7천~\"), lifestyle (≤12 chars)\n",
    "- health_focus, price_sensitivity, brand_loyalty, online_offline_mix, promo_reactivity,\n",
    "  ad_reach_susceptibility, environmental_concern, innovation_seeker (0~1)\n",
    "- channel_preference in {channel_vocab}\n",
    "- weights: map **≥10** of {attribute_list} to weights in [-2.0, +2.0] (utility contribution for THIS product)\n",
    "- monthly_pattern: list[12] for 2024-07..2025-06 in 0.6~1.4 (persona seasonality)\n",
    "\n",
    "Constraints: diversify personas; JSON only (no comments/trailing commas).\n",
    "\"\"\").strip()\n",
    "\n",
    "CHANNELS_VOCAB = ['hypermarket','convenience','ecommerce','SSM']\n",
    "\n",
    "def _build_single_turn_prompt(category, concept, price, pack, channels, competitors, market_size, channel_vocab):\n",
    "    return SINGLE_TURN_PERSONA_PROMPT.format(\n",
    "        category=category, concept=concept, price=price, pack=pack,\n",
    "        channels=\", \".join(channels), competitors=\", \".join(competitors),\n",
    "        market_size=f\"{market_size:,}\", channel_vocab=channel_vocab, attribute_list=ATTRIBUTES\n",
    "    )\n",
    "\n",
    "def save_single_turn_prompt(category, concept, price, pack, channels, competitors, market_size, channel_vocab):\n",
    "    text = _build_single_turn_prompt(category, concept, price, pack, channels, competitors, market_size, channel_vocab)\n",
    "    with open('persona_single_turn_prompt.txt','w',encoding='utf-8') as f: f.write(text)\n",
    "    if _HAS_RL:\n",
    "        c = pdfcanvas.Canvas('persona_single_turn_prompt.pdf', pagesize=A4)\n",
    "        w,h = A4; y=h-50\n",
    "        for line in text.split('\\n'):\n",
    "            while len(line)>100:\n",
    "                c.drawString(40,y,line[:100]); y-=14; line=line[100:]; \n",
    "                if y<50: c.showPage(); y=h-50\n",
    "            c.drawString(40,y,line); y-=14\n",
    "            if y<50: c.showPage(); y=h-50\n",
    "        c.save()\n",
    "\n",
    "# ---------- (선택) LLM adapter (Gemini, robust JSON extraction) ----------\n",
    "# 무료로 하려면 use_llm=False 사용, 또는 오픈소스 LLM(별도)로 JSON 생성 후 캐시 사용 권장.\n",
    "import os, re\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    _HAS_GEMINI = True\n",
    "except Exception:\n",
    "    _HAS_GEMINI = False\n",
    "\n",
    "class LLMAdapter:\n",
    "    def __init__(self, model=\"gemini-1.5-flash-latest\"):\n",
    "        if not _HAS_GEMINI:\n",
    "            raise RuntimeError(\"google-generativeai 미설치. 무료 사용시 use_llm=False 권장.\")\n",
    "        self.model = model\n",
    "        api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise RuntimeError(\"환경변수 GOOGLE_API_KEY 가 없음.\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model_client = genai.GenerativeModel(self.model)\n",
    "\n",
    "    def _extract_json_array(self, text: str) -> list:\n",
    "        text = text.strip()\n",
    "        text = re.sub(r\"^```(?:json)?\\s*\", \"\", text)\n",
    "        text = re.sub(r\"\\s*```$\", \"\", text)\n",
    "        m = re.search(r\"\\[\\s*{.*}\\s*\\]\", text, flags=re.S)\n",
    "        if not m:\n",
    "            raise ValueError(\"LLM 출력에서 JSON 배열을 찾지 못했습니다.\")\n",
    "        return json.loads(m.group(0))\n",
    "\n",
    "    def generate(self, n:int, prompt:str):\n",
    "        msg = prompt.replace(\"Generate N\", f\"Generate {n}\")\n",
    "        try:\n",
    "            rsp = self.model_client.generate_content(msg)\n",
    "            text = getattr(rsp, \"text\", None)\n",
    "            if not text:\n",
    "                try:\n",
    "                    parts = rsp.candidates[0].content.parts\n",
    "                    text = \"\".join(getattr(p, \"text\", \"\") for p in parts)\n",
    "                except Exception:\n",
    "                    text = \"\"\n",
    "            data = self._extract_json_array(text)\n",
    "            return [Persona(**d) for d in data]\n",
    "        except Exception as e:\n",
    "            print(f\"[LLMAdapter] Gemini 파싱 실패: {e} → 규칙기반으로 폴백\")\n",
    "            return None  # 호출부에서 rule-based로 폴백\n",
    "\n",
    "# ---------- Rule-based personas ----------\n",
    "GENDERS=['남','여']; REGIONS=['서울','수도권','광역시','기타']\n",
    "INCOME=['~2천','2-4천','4-7천','7천~']; LIFESTYLES=['활동적','가성비','워라밸','건강지향','육아','미식','트렌디','야근많음']\n",
    "\n",
    "def _rand_weights()->Dict[str,float]:\n",
    "    return {a: float(np.clip(np.random.normal(0,0.7),-2,2)) for a in ATTRIBUTES}\n",
    "\n",
    "def _rand_monthly_pattern()->List[float]:\n",
    "    base=np.ones(12)\n",
    "    for k,v in {2:1.08, 8:1.10, 9:1.06}.items(): base[k]*=v  # 설/추석 부근\n",
    "    base*=np.random.normal(1.0,0.05,12)\n",
    "    pat=(base/base.mean())\n",
    "    return list(np.clip(pat,0.6,1.4))\n",
    "\n",
    "def generate_personas_rule_based(n:int)->List[Persona]:\n",
    "    out=[]\n",
    "    # (선택) 간단 층화: 연령대/성별 분포 타깃을 대략 반영할 수도 있음 (여기선 간략)\n",
    "    for i in range(n):\n",
    "        out.append(Persona(\n",
    "            persona_id=f\"P{i+1:03d}\", name=f\"홍길{'동' if i%2==0 else '순'}{i%10}\",\n",
    "            age=int(np.random.randint(20,66)), gender=random.choice(GENDERS),\n",
    "            region=random.choice(REGIONS), household_size=int(np.random.randint(1,5)),\n",
    "            income_band=random.choice(INCOME), lifestyle=random.choice(LIFESTYLES),\n",
    "            health_focus=float(np.clip(np.random.beta(2,3),0,1)),\n",
    "            price_sensitivity=float(np.clip(np.random.beta(3,2),0,1)),\n",
    "            brand_loyalty=float(np.clip(np.random.beta(2,4),0,1)),\n",
    "            online_offline_mix=float(np.random.rand()),\n",
    "            channel_preference=random.choice(CHANNELS_VOCAB),\n",
    "            promo_reactivity=float(np.clip(np.random.beta(2,2),0,1)),\n",
    "            ad_reach_susceptibility=float(np.clip(np.random.beta(2,2),0,1)),\n",
    "            environmental_concern=float(np.clip(np.random.beta(2,3),0,1)),\n",
    "            innovation_seeker=float(np.clip(np.random.beta(2,2),0,1)),\n",
    "            weights=_rand_weights(), monthly_pattern=_rand_monthly_pattern()\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "# ---------- Demand model ----------\n",
    "@dataclass\n",
    "class MarketCalendar:\n",
    "    price_krw:Dict[pd.Period,float]\n",
    "    discount_rate:Dict[pd.Period,float]\n",
    "    ad_grps:Dict[pd.Period,float]\n",
    "    distribution:Dict[pd.Period,float]\n",
    "    competitor_pressure:Dict[pd.Period,float]\n",
    "    category_season:Dict[pd.Period,float]          # 추가: 카테고리 시즌성(=1.0 기본)\n",
    "\n",
    "def default_calendar(base_price:int=3500)->MarketCalendar:\n",
    "    price={m:float(base_price) for m in MONTHS}\n",
    "    disc={m:(0.12 if m.month in (9,10,2) else 0.0) for m in MONTHS}\n",
    "    ad={m:200.0 for m in MONTHS}\n",
    "    for m in MONTHS:\n",
    "        if m.month in (7,8): ad[m]=400.0\n",
    "    dist={m:min(1.0,0.35+0.08*i) for i,m in enumerate(MONTHS)}\n",
    "    comp={m:1.0 for m in MONTHS}\n",
    "    seas={m:1.0 for m in MONTHS}\n",
    "    return MarketCalendar(price,disc,ad,dist,comp,seas)\n",
    "\n",
    "# ---- 카테고리 시즌성 훅 ----\n",
    "CATEGORY_SEASON = {\n",
    "    '발효유': [1.05,1.08,1.07,1.03,1.02,1.00,0.98,0.97,0.99,1.02,1.03,1.04],\n",
    "    '참치':   [0.95,0.98,1.02,1.00,1.03,1.05,1.06,1.08,1.12,1.10,1.03,0.98],\n",
    "    '조미료': [0.96,0.97,0.98,1.00,1.01,1.02,1.03,1.05,1.08,1.12,1.10,1.00],\n",
    "    '축산캔': [0.99,1.00,1.01,1.01,1.02,1.02,1.03,1.05,1.06,1.08,1.04,1.00],\n",
    "    '커피':   [0.98,1.00,1.02,1.03,1.04,1.06,1.08,1.07,1.03,1.00,0.98,0.97],\n",
    "}\n",
    "def apply_category_seasonality(cal: MarketCalendar, category2: str):\n",
    "    key = None\n",
    "    for k in CATEGORY_SEASON:\n",
    "        if k in str(category2):\n",
    "            key = k; break\n",
    "    if not key: return\n",
    "    idx = CATEGORY_SEASON[key]\n",
    "    for i,m in enumerate(MONTHS):\n",
    "        cal.category_season[m] = float(idx[i])\n",
    "\n",
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    population:int; base_awareness:float; base_trial_rate:float; repeat_rate:float\n",
    "    price_elasticity:float; ad_effect_per_100grp:float; promo_price_pass_through:float; noise_sd:float=0.05\n",
    "    product_multiplier: float = 1.0  # 제품별 소폭 보정(캘리브 전용)\n",
    "\n",
    "def _sigmoid(x:float)->float: return 1/(1+math.exp(-x))\n",
    "\n",
    "# ---- 채널/특징 정합도 보상 ----\n",
    "def _channel_fit(p: Persona, channels: List[str])->float:\n",
    "    return 0.1 if p.channel_preference in channels else -0.05\n",
    "\n",
    "def _feature_match_bonus(p: Persona, feat: str)->float:\n",
    "    bonus=0.0\n",
    "    if '고단백' in feat: bonus += 0.15*(p.health_focus - 0.5)\n",
    "    if ('저당' in feat) or ('저나트륨' in feat): bonus += 0.12*(p.health_focus - 0.5)\n",
    "    if '락토프리' in feat: bonus += 0.12*(p.health_focus - 0.5)\n",
    "    if '프리미엄' in feat: bonus += 0.10*(p.innovation_seeker - 0.5)\n",
    "    return bonus\n",
    "\n",
    "import math\n",
    "def _persona_utility(p:Persona, mi:int, cfg:SimulationConfig, cal:MarketCalendar, period:pd.Period,\n",
    "                     current_channels:List[str], feature_text:str)->float:\n",
    "    wsum=0.0\n",
    "    for k,v in p.weights.items():\n",
    "        val=getattr(p,k,None)\n",
    "        if val is None: continue\n",
    "        if isinstance(val,str) and k in ('gender','region','income_band','channel_preference','lifestyle'):\n",
    "            val_num=(hash((k,val))%7)/6.0\n",
    "        else:\n",
    "            val_num=float(val) if not isinstance(val,str) else 0.5\n",
    "        wsum+=v*val_num\n",
    "    season=p.monthly_pattern[mi]\n",
    "    ad=cfg.ad_effect_per_100grp*(cal.ad_grps[period]/100.0)*p.ad_reach_susceptibility\n",
    "    net_price=cal.price_krw[period]*(1.0-cfg.promo_price_pass_through*cal.discount_rate[period])\n",
    "    price_term=cfg.price_elasticity*math.log(max(net_price,1.0)/1000.0)*p.price_sensitivity\n",
    "    comp=math.log(cal.competitor_pressure[period])\n",
    "    dist=0.1*cal.distribution[period]\n",
    "    # 카테고리 시즌성(1.0 기준)을 유틸리티 가산으로 반영\n",
    "    cat_season_term = 0.15*(cal.category_season.get(period,1.0)-1.0)\n",
    "    # 채널/특징 정합도\n",
    "    channel_term = _channel_fit(p, current_channels)\n",
    "    feature_term = _feature_match_bonus(p, feature_text)\n",
    "    return wsum + ad + dist + (-0.3*comp) - 0.5 + 0.2*season + price_term + cat_season_term + channel_term + feature_term\n",
    "\n",
    "def simulate_monthly_demand(personas:List[Persona], cfg:SimulationConfig, cal:MarketCalendar,\n",
    "                            current_channels:List[str], feature_text:str,\n",
    "                            export_csv=True)->pd.DataFrame:\n",
    "    rows=[]; cum_trials=0.0\n",
    "    for mi,period in enumerate(MONTHS):\n",
    "        probs=[]\n",
    "        for p in personas:\n",
    "            u=_persona_utility(p,mi,cfg,cal,period,current_channels,feature_text)\n",
    "            base=_sigmoid(u)\n",
    "            aware=min(1.0, cfg.base_awareness+0.15*(mi/11.0))\n",
    "            trial=cfg.base_trial_rate*base\n",
    "            probs.append(aware*trial*cal.distribution[period])\n",
    "        exp_trials=cfg.population*np.mean(probs)*cfg.product_multiplier\n",
    "        cum_trials+=exp_trials\n",
    "        repeats=cfg.repeat_rate*cum_trials*0.2\n",
    "        demand=max(0.0,(exp_trials+repeats)*math.exp(np.random.normal(0,cfg.noise_sd)))\n",
    "        rows.append({'month':period.to_timestamp('M'),\n",
    "                     'trial_units':exp_trials,'repeat_units':repeats,'total_units':demand,\n",
    "                     'distribution':cal.distribution[period],'avg_price':cal.price_krw[period],\n",
    "                     'discount_rate':cal.discount_rate[period],'ad_grps':cal.ad_grps[period],\n",
    "                     'category_season':cal.category_season.get(period,1.0)})\n",
    "    df=pd.DataFrame(rows)\n",
    "    if export_csv: df.to_csv('monthly_forecast.csv',index=False)\n",
    "    return df\n",
    "\n",
    "# ---------- 텍스트 → 가격/GRP/ACV ----------\n",
    "_PREMIUM_TABLE={'프리미엄':0.10,'고단백':0.08,'락토프리':0.07,'저나트륨':0.03,'유기':0.05,'친환경':0.05}\n",
    "_BASE_UNIT_PRICE={'참치캔':2000/100.0,'액상조미료':900/100.0,'발효유':1100/100.0,'커피-CUP':640/100.0,'고급축산캔':2200/100.0}\n",
    "\n",
    "def _extract_size(name:str)->Tuple[float,str]:\n",
    "    m=re.search(r'(\\d+(?:\\.\\d+)?)\\s*(g|ml|mL|G|ML)', name)\n",
    "    if not m:\n",
    "        if '커피' in name: return 250.0,'mL'\n",
    "        if '요거트' in name or '발효유' in name: return 400.0,'g'\n",
    "        if '참치' in name: return 90.0,'g'\n",
    "        if '조미' in name: return 500.0,'g'\n",
    "        if '축산' in name: return 200.0,'g'\n",
    "        return 180.0,'g'\n",
    "    v,u=float(m.group(1)),m.group(2).lower()\n",
    "    return v, ('mL' if 'ml' in u else 'g')\n",
    "\n",
    "def _estimate_list_price(row:pd.Series)->int:\n",
    "    name=str(row.get('product_name','')); feat=str(row.get('product_feature',''))\n",
    "    c2=str(row.get('category_level_2','')); c3=str(row.get('category_level_3',''))\n",
    "    size,unit=_extract_size(name)\n",
    "    if '참치캔' in c3 or '참치' in c2: per=_BASE_UNIT_PRICE['참치캔']\n",
    "    elif '조미료' in c3: per=_BASE_UNIT_PRICE['액상조미료']\n",
    "    elif '발효유' in c2 or '요거트' in name: per=_BASE_UNIT_PRICE['발효유']\n",
    "    elif '커피' in c2 or 'CUP' in c3: per=_BASE_UNIT_PRICE['커피-CUP']\n",
    "    elif '축산캔' in c2: per=_BASE_UNIT_PRICE['고급축산캔']\n",
    "    else: per=1000/100.0\n",
    "    price=per*size\n",
    "    prem=sum(v for k,v in _PREMIUM_TABLE.items() if k in feat)\n",
    "    if '프리미엄' in name: prem+=0.10\n",
    "    return int(round(price*(1.0+prem),-1))\n",
    "\n",
    "def _parse_month_ranges(text:str)->List[int]:\n",
    "    res=[]\n",
    "    for m in re.finditer(r'(\\d{1,2})\\s*-\\s*(\\d{1,2})\\s*월', text): a,b=int(m.group(1)),int(m.group(2)); res+=list(range(a,b+1))\n",
    "    for m in re.finditer(r'(?<!-)\\b(\\d{1,2})\\s*월', text): res.append(int(m.group(1)))\n",
    "    return sorted(set([x for x in res if 1<=x<=12]))\n",
    "\n",
    "def enrich_calendar_from_features(cal:MarketCalendar, feat:str, name:str)->None:\n",
    "    months={m.month:m for m in MONTHS}; lower=feat.lower()\n",
    "    for m in MONTHS: cal.ad_grps[m]=200.0\n",
    "    if '광고 x' in lower or '광고x' in lower:\n",
    "        for m in MONTHS: cal.ad_grps[m]=120.0\n",
    "    if any(k in lower for k in ['광고 진행','tv','youtube','sns']):\n",
    "        for mm in _parse_month_ranges(feat):\n",
    "            if mm in months: cal.ad_grps[months[mm]]=max(cal.ad_grps[months[mm]],450.0)\n",
    "    if '엘리베이터 광고' in feat:\n",
    "        for mm in _parse_month_ranges(feat):\n",
    "            if mm in months: cal.ad_grps[months[mm]]+=100.0\n",
    "    if 'sns 바이럴' in feat:\n",
    "        for mm in _parse_month_ranges(feat):\n",
    "            if mm in months: cal.ad_grps[months[mm]]=max(cal.ad_grps[months[mm]],250.0)\n",
    "    for m in MONTHS: cal.discount_rate[m]=0.12 if m.month in (9,10,2) else 0.0\n",
    "    if any(k in feat for k in ['행사','프로모션','기획']):\n",
    "        for mm in _parse_month_ranges(feat):\n",
    "            if mm in months: cal.discount_rate[months[mm]]=min(0.2, cal.discount_rate[months[mm]]+0.05)\n",
    "    start,step=0.35,0.08\n",
    "    if any(k in name for k in ['CUP','컵','커피']): start,step=0.45,0.10\n",
    "    if '엘리베이터 광고' in feat and any(mm in (6,7,8) for mm in _parse_month_ranges(feat)): start+=0.05\n",
    "    cal.distribution={m:min(1.0,start+step*i) for i,m in enumerate(MONTHS)}\n",
    "\n",
    "# ---------- Heuristics ----------\n",
    "def _infer_channels(c1,c2,c3):\n",
    "    if '발효유' in str(c2): return ['hypermarket','convenience']\n",
    "    if '참치' in str(c2):   return ['hypermarket','SSM','ecommerce']\n",
    "    if '조미료' in str(c3): return ['hypermarket','ecommerce']\n",
    "    if '축산캔' in str(c2): return ['hypermarket','SSM','ecommerce']\n",
    "    if '커피' in str(c2):   return ['convenience','hypermarket']\n",
    "    return ['hypermarket','ecommerce']\n",
    "\n",
    "def _infer_competitors(c2):\n",
    "    if '참치' in str(c2): return ['CJ','오뚜기','사조']\n",
    "    if '조미'  in str(c2): return ['CJ','오뚜기']\n",
    "    if '발효유' in str(c2): return ['빙그레','매일','남양']\n",
    "    if '축산캔' in str(c2): return ['SPAM','롯데','동원']\n",
    "    if '커피' in str(c2):   return ['매일','동서','스타벅스RTD']\n",
    "    return ['CJ','오뚜기','사조']\n",
    "\n",
    "def _infer_market_size(name:str,c2:str='')->int:\n",
    "    base=6_000_000\n",
    "    if '발효유' in c2 or '요거트' in name: base=3_000_000\n",
    "    elif '참치' in c2: base=10_000_000\n",
    "    elif '조미' in c2: base=5_000_000\n",
    "    elif '축산캔' in c2: base=4_000_000\n",
    "    elif '커피' in c2: base=12_000_000\n",
    "    h=(abs(hash(name))%41)/100.0\n",
    "    return int(base*(0.8+h))\n",
    "\n",
    "# ---------- Calibrated params 로드 (있으면 사용) ----------\n",
    "CALIB_PATH = \"calibrated_theta.json\"\n",
    "def load_calibrated_theta()->Optional[dict]:\n",
    "    if os.path.exists(CALIB_PATH):\n",
    "        try:\n",
    "            with open(CALIB_PATH,\"r\",encoding=\"utf-8\") as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# ---------- Scenario runner ----------\n",
    "def run_scenario(persona_count:int=400, use_llm:bool=False,\n",
    "                 category:str='식품', concept:str='신제품',\n",
    "                 price:int=3500, pack:str='unit',\n",
    "                 channels:List[str]=['hypermarket','convenience','ecommerce'],\n",
    "                 competitors:List[str]=['CJ','오뚜기','사조'],\n",
    "                 market_size:int=3_200_000,\n",
    "                 calendar:Optional[MarketCalendar]=None,\n",
    "                 ad_effect_mult:float=1.0,\n",
    "                 feature_text:str=\"\"\n",
    "                 ):\n",
    "    save_single_turn_prompt(category, concept, price, pack, channels, competitors, market_size, CHANNELS_VOCAB)\n",
    "\n",
    "    personas = None\n",
    "    if use_llm:\n",
    "        try:\n",
    "            personas = LLMAdapter().generate(persona_count,\n",
    "                        _build_single_turn_prompt(category,concept,price,pack,channels,competitors,market_size,CHANNELS_VOCAB))\n",
    "        except Exception as e:\n",
    "            print(f\"[run_scenario] LLM 사용 실패: {e} → 규칙기반으로 진행\")\n",
    "    if personas is None:\n",
    "        personas = generate_personas_rule_based(persona_count)\n",
    "\n",
    "    cal = calendar or default_calendar(price)\n",
    "\n",
    "    # 캘리브 파라미터 로드(있으면 우선적용)\n",
    "    theta = load_calibrated_theta()\n",
    "    if theta:\n",
    "        base_awareness    = float(theta.get(\"base_awareness\", 0.18))\n",
    "        base_trial_rate   = float(theta.get(\"base_trial_rate\", 0.35))\n",
    "        repeat_rate       = float(theta.get(\"repeat_rate\", 0.55))\n",
    "        price_elasticity  = float(theta.get(\"price_elasticity\", -1.2))\n",
    "        ad_effect_k       = float(theta.get(\"ad_effect_per_100grp\", 0.10))*ad_effect_mult\n",
    "        promo_pass        = float(theta.get(\"promo_price_pass_through\", 0.8))\n",
    "        product_mult      = float(theta.get(\"product_multiplier\", 1.0))\n",
    "    else:\n",
    "        base_awareness, base_trial_rate, repeat_rate = 0.18, 0.35, 0.55\n",
    "        price_elasticity, ad_effect_k, promo_pass = -1.2, 0.10*ad_effect_mult, 0.8\n",
    "        product_mult = 1.0\n",
    "\n",
    "    cfg = SimulationConfig(\n",
    "        population=market_size,\n",
    "        base_awareness=base_awareness,\n",
    "        base_trial_rate=base_trial_rate,\n",
    "        repeat_rate=repeat_rate,\n",
    "        price_elasticity=price_elasticity,\n",
    "        ad_effect_per_100grp=ad_effect_k,\n",
    "        promo_price_pass_through=promo_pass,\n",
    "        noise_sd=0.06,\n",
    "        product_multiplier=product_mult\n",
    "    )\n",
    "    forecast=simulate_monthly_demand(personas, cfg, cal, channels, feature_text, export_csv=True)\n",
    "    SOURCES.to_json('sources_used.json'); _write_solution_outline(forecast, persona_count, category, concept, price, pack)\n",
    "    return forecast, personas\n",
    "\n",
    "def _write_solution_outline(forecast:pd.DataFrame, persona_count:int, category:str, concept:str, price:int, pack:str):\n",
    "    last=forecast.tail(1).iloc[0]\n",
    "    md=(f\"# 솔루션 설명 자료(초안)\\n\"\n",
    "        f\"## 개요\\n- 카테고리:{category}\\n- 컨셉:{concept}\\n- 가격:{price:,} / {pack}\\n- 페르소나:{persona_count}\\n\"\n",
    "        f\"## 핵심결과\\n- 12M 합계:{int(forecast['total_units'].sum()):,} EA\\n\"\n",
    "        f\"- 런칭월:{int(forecast.iloc[0]['total_units']):,} EA\\n- 최종월:{int(last['total_units']):,} EA\\n\")\n",
    "    with open('solution_report.md','w',encoding='utf-8') as f: f.write(md)\n",
    "\n",
    "# ---------- One product → 12m (MC 앙상블 지원) ----------\n",
    "def forecast_one_product(row:pd.Series, persona_count:int=400, use_llm:bool=False, mc_runs:int=7)->np.ndarray:\n",
    "    global RNG\n",
    "    name=str(row.get('product_name','')).strip()\n",
    "    feat=str(row.get('product_feature','')).strip()\n",
    "    c1=str(row.get('category_level_1','')); c2=str(row.get('category_level_2','')); c3=str(row.get('category_level_3',''))\n",
    "\n",
    "    # 제품별 시드 고정\n",
    "    seed=abs(hash(name))%(2**32-1)\n",
    "    # 가격/시장/채널\n",
    "    price=_estimate_list_price(row)\n",
    "    market_size=_infer_market_size(name,c2); channels=_infer_channels(c1,c2,c3); competitors=_infer_competitors(c2)\n",
    "    # 캘린더 구성\n",
    "    cal=default_calendar(price); enrich_calendar_from_features(cal, feat, name); apply_category_seasonality(cal, c2)\n",
    "    # 유명인 보정(광고효과 가중)\n",
    "    ad_mult=1.0\n",
    "    if '광고모델' in feat and any(k in feat for k in ['안유진','아이돌','연예인']): ad_mult=1.15\n",
    "    # 패키지 텍스트\n",
    "    size,unit=_extract_size(name); pack=f\"{int(size)}{unit}\"\n",
    "\n",
    "    # Monte Carlo 앙상블: seed 변화로 여러 번 → 월별 중앙값 사용\n",
    "    preds=[]\n",
    "    for r in range(mc_runs):\n",
    "        RNG=np.random.default_rng(seed + r*1337); random.seed(seed + r*7331)\n",
    "        df,_=run_scenario(persona_count, use_llm, c1 or '식품', feat[:80] or '신제품',\n",
    "                          price, pack, channels, competitors, market_size, cal, ad_mult, feature_text=feat)\n",
    "        preds.append(np.maximum(0, np.array(df['total_units'].values)))\n",
    "    y = np.rint(np.median(np.stack(preds, axis=0), axis=0)).astype(int)\n",
    "    return y\n",
    "\n",
    "# ---------- Submission ----------\n",
    "def make_submission(product_info_csv:str, out_csv:str='submission.csv', persona_count:int=400,\n",
    "                    use_llm:bool=False, mc_runs:int=7)->pd.DataFrame:\n",
    "    prod=pd.read_csv(product_info_csv)\n",
    "    rows=[]\n",
    "    for _,row in prod.iterrows():\n",
    "        y=forecast_one_product(row, persona_count, use_llm, mc_runs=mc_runs)\n",
    "        rows.append({'product_name':row['product_name'],\n",
    "                     **{f'months_since_launch_{i+1}':int(y[i]) for i in range(12)}})\n",
    "    sub=pd.DataFrame(rows)\n",
    "    sub.to_csv(out_csv,index=False)\n",
    "    return sub\n",
    "\n",
    "# ---------- (선택) 간단 캘리브레이션 골격 ----------\n",
    "# 유사제품의 과거 월별 판매(y_true: 12개)와 템플릿 캘린더/페르소나를 넣고\n",
    "# theta를 탐색해 calibrated_theta.json 저장하는 자리. 실제 y_true가 있을 때만 사용.\n",
    "def simple_calibrate(y_true: np.ndarray,\n",
    "                     personas: List[Persona],\n",
    "                     cal_template: MarketCalendar,\n",
    "                     init: dict = None,\n",
    "                     bounds: dict = None):\n",
    "    \"\"\"\n",
    "    y_true: (12,) 실측 또는 프록시 월별 판매\n",
    "    init:   초기값 딕트, 없으면 기본\n",
    "    bounds: (lo, hi) 딕트\n",
    "    \"\"\"\n",
    "    from scipy.optimize import minimize\n",
    "    init = init or dict(base_awareness=0.18, base_trial_rate=0.35, repeat_rate=0.55,\n",
    "                        price_elasticity=-1.2, ad_effect_per_100grp=0.10,\n",
    "                        promo_price_pass_through=0.8, product_multiplier=1.0)\n",
    "    bounds = bounds or dict(\n",
    "        base_awareness=(0.05,0.6), base_trial_rate=(0.05,0.8), repeat_rate=(0.2,0.8),\n",
    "        price_elasticity=(-2.5,-0.2), ad_effect_per_100grp=(0.02,0.25),\n",
    "        promo_price_pass_through=(0.5,0.95), product_multiplier=(0.6,1.6)\n",
    "    )\n",
    "\n",
    "    keys = list(init.keys())\n",
    "    x0 = np.array([init[k] for k in keys])\n",
    "    lo = np.array([bounds[k][0] for k in keys])\n",
    "    hi = np.array([bounds[k][1] for k in keys])\n",
    "\n",
    "    channels = ['hypermarket','convenience','ecommerce']\n",
    "    feat_text = \"\"\n",
    "\n",
    "    def pack(theta):\n",
    "        return {k: float(v) for k,v in zip(keys, theta)}\n",
    "\n",
    "    def clamp(theta):\n",
    "        return np.minimum(np.maximum(theta, lo), hi)\n",
    "\n",
    "    def simulate_theta(theta):\n",
    "        th = pack(theta)\n",
    "        cfg = SimulationConfig(\n",
    "            population=3_000_000,\n",
    "            base_awareness=th['base_awareness'],\n",
    "            base_trial_rate=th['base_trial_rate'],\n",
    "            repeat_rate=th['repeat_rate'],\n",
    "            price_elasticity=th['price_elasticity'],\n",
    "            ad_effect_per_100grp=th['ad_effect_per_100grp'],\n",
    "            promo_price_pass_through=th['promo_price_pass_through'],\n",
    "            noise_sd=0.0,\n",
    "            product_multiplier=th['product_multiplier']\n",
    "        )\n",
    "        df = simulate_monthly_demand(personas, cfg, cal_template, channels, feat_text, export_csv=False)\n",
    "        return df['total_units'].values\n",
    "\n",
    "    def loss(theta):\n",
    "        theta = clamp(theta)\n",
    "        y_pred = simulate_theta(theta)\n",
    "        mape = np.mean(np.abs(y_true - y_pred) / (y_true + 1))\n",
    "        reg = 1e-3*np.sum((theta - x0)**2)  # 약한 규제\n",
    "        return float(mape + reg)\n",
    "\n",
    "    res = minimize(loss, x0, method='Nelder-Mead', options={'maxiter':300})\n",
    "    theta_opt = pack(clamp(res.x))\n",
    "    with open(CALIB_PATH,'w',encoding='utf-8') as f: json.dump(theta_opt,f,ensure_ascii=False,indent=2)\n",
    "    print(\"Saved calibrated params ->\", CALIB_PATH)\n",
    "    return theta_opt\n",
    "\n",
    "# ---------- main ----------\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # 개발 중에는 무료로: use_llm=False, mc_runs=7~21 권장\n",
    "        sub=make_submission('product_info.csv','submission.csv',\n",
    "                            persona_count=400, use_llm=True, mc_runs=5)\n",
    "        print(sub.head())\n",
    "        print(\"Files: submission.csv, monthly_forecast.csv, persona_single_turn_prompt.txt/.pdf, sources_used.json, solution_report.md\")\n",
    "    except Exception as e:\n",
    "        print(\"Run make_submission(...) with correct CSV. Error:\",e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45348e6-12c6-483a-870f-407c92fca97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1. category_prices.csv 생성 (API 버전 예시)\n",
    "import requests, pandas as pd, datetime\n",
    "\n",
    "CLIENT_ID = \"12A3OnjYdiu2_EY_DkwS\"\n",
    "CLIENT_SECRET = \"p4qammTuR1\"\n",
    "\n",
    "def naver_price_search(query):\n",
    "    url = \"https://openapi.naver.com/v1/search/shop.json\"\n",
    "    headers = {\"X-Naver-Client-Id\": CLIENT_ID, \"X-Naver-Client-Secret\": CLIENT_SECRET}\n",
    "    params = {\"query\": query, \"display\": 3, \"sort\": \"sim\"}\n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    if resp.status_code != 200: return None\n",
    "    items = resp.json().get(\"items\", [])\n",
    "    if not items: return None\n",
    "    prices = [int(it[\"lprice\"]) for it in items]\n",
    "    return min(prices) if prices else None\n",
    "\n",
    "def build_category_prices(product_info_csv, out_csv=\"category_prices.csv\"):\n",
    "    prod = pd.read_csv(product_info_csv)\n",
    "    rows = []\n",
    "    for _, row in prod.iterrows():\n",
    "        name = str(row[\"product_name\"])\n",
    "        query = f\"{name}\"\n",
    "        price = naver_price_search(query)\n",
    "        rows.append({\n",
    "            \"product_name\": name,\n",
    "            \"category_level_1\": row[\"category_level_1\"],\n",
    "            \"category_level_2\": row[\"category_level_2\"],\n",
    "            \"category_level_3\": row[\"category_level_3\"],\n",
    "            \"pack_size_value\": int(''.join([c for c in name if c.isdigit()]) or 0),\n",
    "            \"pack_size_unit\": \"g\" if \"g\" in name.lower() else \"ml\",\n",
    "            \"list_price\": price,\n",
    "            \"channel\": \"네이버쇼핑\",\n",
    "            \"observed_at\": datetime.date.today().isoformat()\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"Saved:\", out_csv)\n",
    "    return df\n",
    "\n",
    "# Step2. LightGBM 학습\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "def train_price_model(csv_path=\"category_prices.csv\"):\n",
    "    df = pd.read_csv(csv_path).dropna(subset=[\"list_price\"])\n",
    "    y = df[\"list_price\"].values\n",
    "\n",
    "    # feature engineering\n",
    "    X = df[[\"pack_size_value\",\"pack_size_unit\",\"category_level_1\",\"category_level_2\",\"category_level_3\",\"product_name\"]].copy()\n",
    "    # 간단하게 pack_size_unit -> 0(g)/1(ml)\n",
    "    X[\"pack_size_unit\"] = X[\"pack_size_unit\"].map({\"g\":0,\"ml\":1,\"mL\":1})\n",
    "    # product_feature 키워드 기반 flag 생성 (프리미엄, 고단백, 락토프리 등)\n",
    "    X[\"is_premium\"] = df[\"product_name\"].str.contains(\"프리미엄\").astype(int)\n",
    "    X[\"is_high_protein\"] = df[\"product_name\"].str.contains(\"고단백\").astype(int)\n",
    "    X[\"is_lactofree\"] = df[\"product_name\"].str.contains(\"락토프리\").astype(int)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.05, max_depth=7)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Train R2:\", model.score(X_train, y_train))\n",
    "    print(\"Test R2:\", model.score(X_test, y_test))\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(model, \"price_model.pkl\")\n",
    "    print(\"Saved price_model.pkl\")\n",
    "    return model\n",
    "\n",
    "# Step3. 기존 코드 교체\n",
    "import joblib\n",
    "def _estimate_list_price(row):\n",
    "    try:\n",
    "        model = joblib.load(\"price_model.pkl\")\n",
    "        size = int(''.join([c for c in str(row[\"product_name\"]) if c.isdigit()]) or 0)\n",
    "        unit = 0 if \"g\" in str(row[\"product_name\"]).lower() else 1\n",
    "        feat = {\n",
    "            \"pack_size_value\": size,\n",
    "            \"pack_size_unit\": unit,\n",
    "            \"category_level_1\": row[\"category_level_1\"],\n",
    "            \"category_level_2\": row[\"category_level_2\"],\n",
    "            \"category_level_3\": row[\"category_level_3\"],\n",
    "            \"is_premium\": int(\"프리미엄\" in row[\"product_feature\"]),\n",
    "            \"is_high_protein\": int(\"고단백\" in row[\"product_feature\"]),\n",
    "            \"is_lactofree\": int(\"락토프리\" in row[\"product_feature\"])\n",
    "        }\n",
    "        X = pd.DataFrame([feat])\n",
    "        return int(model.predict(X)[0])\n",
    "    except Exception as e:\n",
    "        print(\"Price model fallback:\", e)\n",
    "        return 3000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e71e93-c593-4e97-9104-2fb0690bfe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- One product → 12m (MC 앙상블 지원) ----------\n",
    "def forecast_one_product(row: pd.Series, persona_count: int = 400, use_llm: bool = False, mc_runs: int = 9) -> np.ndarray:\n",
    "    global RNG\n",
    "    name = str(row.get('product_name', '')).strip()\n",
    "    feat = str(row.get('product_feature', '')).strip()\n",
    "    c1 = str(row.get('category_level_1', ''))\n",
    "    c2 = str(row.get('category_level_2', ''))\n",
    "    c3 = str(row.get('category_level_3', ''))\n",
    "\n",
    "    # 제품별 시드 고정\n",
    "    seed = abs(hash(name)) % (2**32 - 1)\n",
    "\n",
    "    # 가격 (ML 모델 기반)\n",
    "    price = _estimate_list_price(row)\n",
    "\n",
    "    # 시장/채널/경쟁사 추론\n",
    "    market_size = _infer_market_size(name, c2)\n",
    "    channels = _infer_channels(c1, c2, c3)\n",
    "    competitors = _infer_competitors(c2)\n",
    "\n",
    "    # 캘린더 구성\n",
    "    cal = default_calendar(price)\n",
    "    enrich_calendar_from_features(cal, feat, name)\n",
    "    apply_category_seasonality(cal, c2)\n",
    "\n",
    "    # 유명인 보정(광고모델 효과)\n",
    "    ad_mult = 1.0\n",
    "    if '광고모델' in feat and any(k in feat for k in ['안유진', '아이돌', '연예인']):\n",
    "        ad_mult = 1.15\n",
    "\n",
    "    # 패키지 텍스트\n",
    "    size, unit = _extract_size(name)\n",
    "    pack = f\"{int(size)}{unit}\"\n",
    "\n",
    "    # Monte Carlo 앙상블 → 월별 중앙값 사용\n",
    "    preds = []\n",
    "    for r in range(mc_runs):\n",
    "        RNG = np.random.default_rng(seed + r * 1337)\n",
    "        random.seed(seed + r * 7331)\n",
    "        df, _ = run_scenario(\n",
    "            persona_count, use_llm,\n",
    "            c1 or '식품', feat[:80] or '신제품',\n",
    "            price, pack, channels, competitors,\n",
    "            market_size, cal, ad_mult, feature_text=feat\n",
    "        )\n",
    "        preds.append(np.maximum(0, np.array(df['total_units'].values)))\n",
    "    y = np.rint(np.median(np.stack(preds, axis=0), axis=0)).astype(int)\n",
    "    return y\n",
    "\n",
    "# ---------- Submission ----------\n",
    "def make_submission(product_info_csv: str, out_csv: str = 'submission.csv', persona_count: int = 400,\n",
    "                    use_llm: bool = False, mc_runs: int = 9) -> pd.DataFrame:\n",
    "    prod = pd.read_csv(product_info_csv)\n",
    "    rows = []\n",
    "    for _, row in prod.iterrows():\n",
    "        y = forecast_one_product(row, persona_count, use_llm, mc_runs=mc_runs)\n",
    "        rows.append({\n",
    "            'product_name': row['product_name'],\n",
    "            **{f'months_since_launch_{i+1}': int(y[i]) for i in range(12)}\n",
    "        })\n",
    "    sub = pd.DataFrame(rows)\n",
    "    sub.to_csv(out_csv, index=False)\n",
    "    print(\"Saved:\", out_csv)\n",
    "    return sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e7ee0-69c3-48e7-9103-f8b631a27f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1. 가격 데이터 수집 → category_prices.csv 생성\n",
    "build_category_prices(\"product_info.csv\", out_csv=\"category_prices.csv\")\n",
    "\n",
    "# Step2. LightGBM 학습\n",
    "train_price_model(\"category_prices.csv\")\n",
    "\n",
    "# Step3. 판매량 예측 실행\n",
    "submission = make_submission(\"product_info.csv\", \"submission.csv\", persona_count=400, use_llm=False, mc_runs=9)\n",
    "\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
